{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문 게시판 스크래핑\n",
    "\n",
    "질문 게시판은 서비스 시작부터 있었던 모든 질문 데이터를 스크래핑해야 하므로 오랜 실행시간이 필요합니다. \n",
    "\n",
    "실행시간이 길기 때문에 '컴퓨터 부하 발생으로 인한 종료' 등의 변수로 스크래핑한 데이터가 저장되지 않는것을 방지하고자 세이브 포인트를 설정하여 50페이지 마다 현재 스크래핑된 데이터를 저장하도록 진행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 97.0.4692\n",
      "Get LATEST chromedriver version for 97.0.4692 google-chrome\n",
      "Driver [C:\\Users\\TaeSoo\\.wdm\\drivers\\chromedriver\\win32\\97.0.4692.71\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(10)\n",
    "driver.get('https://www.inflearn.com/community/questions')\n",
    "time.sleep(2)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = bs(html, 'html.parser')  \n",
    "\n",
    "# 질문 게시글 제목 / 질문자 / 질문 날짜 / 질문 내용 / 강의 제목 / 강의 섹션 / 답변자 / 답변 날짜 / 답변 내용\n",
    "title_, questioner_, q_date_, q_content_, course_title_, section_, answer_, a_date_, a_content_ = [[] for i in range(9)]\n",
    "\n",
    "last_page = int(soup.select_one('#main > section.community-body > div.community-body__content > nav > ul > li:nth-of-type(12) > a').text)\n",
    "save_point = [(50 * i) for i in range(1, math.ceil(last_page/50))]\n",
    "\n",
    "for i in range(last_page) :\n",
    "    \n",
    "    page = str(i + 1)\n",
    "    url = 'https://www.inflearn.com/community/questions?page=' + page\n",
    "    driver.get(url)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'html.parser')   \n",
    "\n",
    "    # 질문 게시글의 url 가져옴\n",
    "    question_list = []\n",
    "    question_container = soup.select('li.question-container')\n",
    "    for container in question_container :\n",
    "        question_list.append(container.select_one('a')['href'].split('/questions/')[1])\n",
    "\n",
    "    # 하나의 게시글마다 스크래핑\n",
    "    for post_id in question_list :\n",
    "\n",
    "        content_url = 'https://www.inflearn.com/questions/' + post_id\n",
    "        driver.get(content_url)\n",
    "\n",
    "        questions_html = driver.page_source        \n",
    "        questions_soup = bs(questions_html, 'html.parser') \n",
    "\n",
    "        title_.append(questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__header > div.header__title > h1').text)\n",
    "        questioner = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__header > div.header__sub-title > h6').text\n",
    "        if (questioner is not None) :\n",
    "            questioner = questioner.replace(', ', '')\n",
    "            questioner_.append(questioner)        \n",
    "\n",
    "        q_date = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__header > div.header__sub-title > span').text\n",
    "        q_date = q_date.replace('\\xa0· ', '')\n",
    "        q_date_.append(q_date)\n",
    "\n",
    "        q_content = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__content > div.content__body.markdown-body').text\n",
    "        if (q_content is not None) :\n",
    "            q_content = q_content.replace('\\n', ' ')\n",
    "            q_content_.append(q_content)\n",
    "\n",
    "        course_title_list = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__content > div.content__sub-info > div.sub-info__item.sub-info__course-unit > div')\n",
    "        course_title = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__content > div.content__sub-info-none-member > a > div > p')\n",
    "        if (course_title is not None) :\n",
    "            course_title_.append(course_title.text)\n",
    "        else :\n",
    "            course_title_.append('None')\n",
    "\n",
    "        section = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__post > div.section__content > div > div.community-post-info__content > div.content__sub-info-none-member > a.sub-info-none-member__unit > p.sub-info-none-member__unit-title')\n",
    "        if (section is not None) :\n",
    "            section_.append(section.text)\n",
    "        else :\n",
    "            section_.append('None')\n",
    "\n",
    "        answer_count = questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__answer > div > div > div.answer-info__header > div').text[4:5]\n",
    "        if (answer_count == '1') :\n",
    "            answer_.append(questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__answer > div > div > div.community-post-info__content > div > div:nth-of-type(1) > div.comment__card > div.comment__header.flex-row > div > div > a').text.replace('\\n', ' '))\n",
    "            a_date_.append(questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__answer > div > div > div.community-post-info__content > div > div:nth-of-type(1) > div.comment__card > div.comment__header.flex-row > div > span').text)\n",
    "            a_content_.append(questions_soup.select_one('#main > section.community-post-detail__section.community-post-detail__answer > div > div > div.community-post-info__content > div > div:nth-of-type(1) > div.comment__card > div.comment__body.markdown-body').text)\n",
    "        elif (answer_count == '0'):\n",
    "            answer_.append('None')\n",
    "            a_date_.append('None')\n",
    "            a_content_.append('None')\n",
    "        else :\n",
    "            answer_list = []\n",
    "            a_date_list = []\n",
    "            a_content_list = []\n",
    "\n",
    "            answers = questions_soup.select('a.comment__user-name')\n",
    "            for answer in answers :\n",
    "                answer_list.append(answer.text.replace('\\n', ' '))\n",
    "            answer_.append(answer_list)\n",
    "\n",
    "            a_dates = questions_soup.select('span.comment__updated-at')\n",
    "            for a_date in a_dates :\n",
    "                a_date_list.append(a_date.text)\n",
    "            a_date_.append(a_date_list)\n",
    "\n",
    "            a_contents = questions_soup.select('p.comment__body markdown-body')\n",
    "            for a_content in a_contents :\n",
    "                a_content_list.append(a_content.text)\n",
    "            a_content_.append(a_content_list)\n",
    "\n",
    "    # 스크래핑 데이터 양이 많고 여러가지 위험 요소를 방비하기 위해 중간중간 세이브 포인트를 삽입\n",
    "\n",
    "    if i in save_point :\n",
    "        q_df = pd.DataFrame(np.array([title_, questioner_, q_date_, q_content_, course_title_, section_, answer_, a_date_, a_content_]), index = ('title', 'questioner', 'q_date', 'q_content', 'course_title', 'section', 'answer', 'a_date', 'a_content'))\n",
    "        q_df = q_df.transpose()\n",
    "        q_df.to_csv('q_' + str(i) + '.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "# 스크래핑된 내용을 저장\n",
    "q_df = pd.DataFrame(np.array([title_, questioner_, q_date_, q_content_, course_title_, section_, answer_, a_date_, a_content_]), index = ('title', 'questioner', 'q_date', 'q_content', 'course_title', 'section', 'answer', 'a_date', 'a_content'))\n",
    "q_df = q_df.transpose()\n",
    "q_df.to_csv('o1_question.csv', encoding = 'utf-8-sig') \n",
    "\n",
    "time.sleep(1)\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73407dee87cc73a13fe6a424f5d316f883ddf267c66cfaad22110334c7428349"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dev_project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
